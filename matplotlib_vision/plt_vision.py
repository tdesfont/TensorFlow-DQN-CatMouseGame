#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
In this particular game, the action-space is continuous due to the space.
Therefore, we have two options to perform our Reinforcement Learning Task:
- Discretize the action-space and consider a grid for the space
- Work directly on the image generated by the game (Atari/OpenAI way...)

To perform the second option, I reused an available code to convert the
matplotlib canvas to an RGB image.

Credits: http://www.icare.univ-lille1.fr/tutorials/convert_a_matplotlib_figure
"""

import numpy as np
import matplotlib.pyplot as plt


def fig2data(fig):
    """
    Convert a Matplotlib figure to a 3D numpy array with RGB channels
    Input:
        fig <matplotlib figure>
    Return:
        3D array of RGB values
    """
    # Draw the renderer
    fig.canvas.draw()
    # Get the RGB buffer from the figure
    w, h = fig.canvas.get_width_height()
    buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    buf.shape = (w, h, 3)
    # Roll the ALPHA channel to have it in RGBA mode
    buf = np.roll(buf, 3, axis=2)
    return buf


def get_screen(position_prey, position_predator):
    """
    Return RGB image from the positions of the prey and predator

    Input:
        position_prey : <list> Position of the prey
        position_predator : <list> Position of the predator
    """
    # Create the figure
    fig = plt.figure(figsize=(3, 3))

    plt.scatter(position_prey[0], position_prey[1], color='r', edgecolor='k')

    plt.scatter(position_predator[0], position_predator[1], color='y',
                edgecolor='k')

    plt.axis('off')
    plt.xlim([-40, 40])
    plt.ylim([-40, 40])
    plt.close()
    # Convert it to RGB-numpy array
    screen = fig2data(fig)
    return screen
